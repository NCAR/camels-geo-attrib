{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute climate indices\n",
    "**Please clean all outputs when committing all the changes in git.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import os, sys\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import scripts.clim_indices as ci\n",
    "import scripts.utility as util\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## 1. Setup <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "setup = util.load_yaml(\"./climate_index_setup.yaml\")\n",
    "\n",
    "catchment_name = setup[\"catchment_name\"]  # Catchment case: CONUS_HUC12 or camels\n",
    "serial = setup[\"serial\"] # True: dask distributed enabled\n",
    "saveCSV = setup[\"saveCSV\"] # True: save attributes for each HRU in csv\n",
    "saveNetCDF = setup[\"saveNetCDF\"] # True: save attributes for each HRU in netcdf\n",
    "remap = setup[\"remap\"] # True: remap meteorological time series to HRUs\n",
    "\n",
    "# files and directories\n",
    "src_dir = setup[\"src_dir\"]\n",
    "catch_gpkg = setup[\"catch_gpkg\"]\n",
    "mapping_file = setup[\"mapping_file\"]\n",
    "aggregate_daily = setup[\"aggregate_daily\"]\n",
    "\n",
    "# climate variable meta\n",
    "variables = setup[\"climate_vars\"]\n",
    "nc_var = [meta['name'] for var, meta in variables.items()]\n",
    "remap_variables = variables\n",
    "\n",
    "# catchment meta\n",
    "catch_attrs = setup[\"catch_attrs\"]\n",
    "\n",
    "print('-- Setup:')\n",
    "print(f\" Dask not enabled: {serial}\")\n",
    "print(f\" catchment_name: {catchment_name}\")\n",
    "print(f\" saveCSV: {saveCSV}\")\n",
    "print(f\" saveNetCDF: {saveNetCDF}\")\n",
    "print(f\" remap: {remap}\")\n",
    "print(f\" climate data directory: {src_dir}\")\n",
    "print(f\" catchment gpkg: {catch_gpkg}\")\n",
    "print(f\" mapping file: {mapping_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = None\n",
    "\n",
    "if not serial:\n",
    "    from dask.distributed import Client\n",
    "    from dask_jobqueue import PBSCluster\n",
    "\n",
    "    cluster = PBSCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        memory=\"50GB\",\n",
    "        queue=\"casper\",\n",
    "        walltime=\"00:30:00\",\n",
    "    )\n",
    "    cluster.scale(jobs=15)\n",
    "    client = Client(cluster)\n",
    "    \n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    ds = ds[nc_var]\n",
    "    for var, meta in variables.items():\n",
    "        ds[meta['name']] = ds[meta['name']]*meta['scale']+meta['offset']\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f'Reading climate data')\n",
    "a = xr.open_mfdataset(os.path.join(src_dir, f'*.nc'), data_vars='minimal', preprocess=preprocess, parallel=True)    # WARNING: read all the netcdfs!!\n",
    "if aggregate_daily:\n",
    "    a = a.resample(time='D').mean()\n",
    "    a[variables['hru_id']['name']] = a[variables['hru_id']['name']].isel(time=0, drop=True)\n",
    "a = a.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-mapping\n",
    "- remapping 7 climate variables\n",
    "\n",
    "**TODO: revise yaml file to incorporate reading gridded climate data. currently trying to read hru assuming the data is remapped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if remap:\n",
    "    a = util.regrid_mean_timeSeries(xr.open_dataset(mapping_file), a, \n",
    "                                    xr.where(np.isnan(a[variables['tair']['name']].isel(time=0)),0,1), \n",
    "                                    list(variables.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.assign_coords(hru=a[variables['hru_id']['name']].astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing climate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pe = ci.Penman(a[variables['sw']['name']], a[variables['lw']['name']], a[variables['wind']['name']], a[variables['tair']['name']], a[variables['q']['name']], a[variables['p']['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[variables['precp']['name']].mean(dim='time').to_dataset(name='p_mean')\n",
    "b['pe_mean'] = pe.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "b = xr.merge([b, ci.seasonality_index(a[variables['tair']['name']], a[variables['precp']['name']])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['aridity'] = pe.mean(dim='time')/a[variables['precp']['name']].mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds1 = ci.high_p_freq_dur(a[variables['precp']['name']]) #, dayofyear='calendar'\n",
    "b['high_prec_freq'] = ds1['high_prec_freq'].mean(dim='year')\n",
    "b['high_prec_dur'] = ds1['high_prec_dur'].mean(dim='year')\n",
    "# Apply the mode function along the 'year' dimension\n",
    "b['high_prec_timing'] = xr.apply_ufunc(\n",
    "    util.mode_func,\n",
    "    ds1['high_prec_timing'],\n",
    "    input_core_dims=[['year']],   # Specify the dimension along which to apply the function\n",
    "    vectorize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds2 = ci.low_p_freq_dur(a[variables['precp']['name']])\n",
    "b['low_prec_dur'] = ds2['low_prec_dur'].mean(dim='year')\n",
    "b['low_prec_freq'] = ds2['low_prec_freq'].mean(dim='year')\n",
    "b['low_prec_timing'] = xr.apply_ufunc(\n",
    "    util.mode_func,\n",
    "    ds2['low_prec_timing'],\n",
    "    input_core_dims=[['year']],   # Specify the dimension along which to apply the function\n",
    "    vectorize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save in csv or netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveCSV:\n",
    "    df.to_csv(os.path.join('output', f'{catchment_name}_clim_test.csv'), float_format='%g')\n",
    "if saveNetCDF:\n",
    "    b.to_netcdf(os.path.join('output', f'{catchment_name}_clim_test.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camels shapefile\n",
    "gdf_camels = util.read_shps([catch_gpkg],[catch_attrs[catchment_name]['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_camels = gdf_camels.merge(df,left_on=catch_attrs[catchment_name]['id'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'p_mean'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo',\n",
    "                norm=colors.Normalize(0, 5),\n",
    "                legend=True\n",
    "               );\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'pe_mean'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo',\n",
    "                norm=colors.Normalize(0, 5),\n",
    "                legend=True\n",
    "               );\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'p_seasonality'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo',\n",
    "                norm=colors.Normalize(-1, 1),\n",
    "                legend=True\n",
    "               );\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'snow_frac'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(0, 0.6),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'aridity'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(0.20, 3.0),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'high_prec_dur'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(1.0, 1.8),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}_new.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'high_prec_freq'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(5, 25),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}_new.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'low_prec_dur'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(1.0, 30),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}_new.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'low_prec_freq'\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=150)\n",
    "gdf_camels.plot(ax=ax, column=var_name, cmap='turbo', \n",
    "                norm=colors.Normalize(200, 365),\n",
    "                legend=True\n",
    ");\n",
    "ax.set_title(var_name);\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'./figures/{catchment_name}_clim_{var_name}_new.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
